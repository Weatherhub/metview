function, of = _, path = (join_strings, separator = "/", _ = (_))

# Function split_and_archive:
#
# - prepares ODB data for archiving by splitting it into several files 
#   with data homogenious with regards to analysis date, time and report type,
#   suitable for indexing on MARS Server / ODB Server.
#
# - archives the files,
#
# - verifies the archiving was successfull by retrieving archived files
#   and comparing them to the originals

# Function split_and_archive accepts 3 parameters:
function,of = filter         # SQL to be applied to input files.
            / source         # List of files to be procesed.
            / output_schema, # Template of output files with ODB columns to split 
                             # the data by in curly braces,
                             # e.g. "/odb_root/{andate}/{antime}/{reportype}.odb"

         split_and_archive = (

            println, values = "******** About to archive" / ($,_ = source) / "*******" 

            let, files = (split,
                            source = ($,_ = source),
                            target = ($,_ = output_schema),
                            filter = ($,_ = filter))

            println,values = "******** Files produced by split:" / ($,_ = files)

            let, mars_handles = (archive,
                                    database = local,
                                    odbpathnameschema = "{date}/{time}/{reportype}.odb",
                                    odbserverroots = "~/data/root",
                                    source = ($,_ = files))

            # Retrieve each file using list of "local://retrieve,..." 
            # URLs produced by archive, and compare them to 
            # original files as produced by split

            compare, left = ($,_ = files), right = ($,_ = mars_handles)

            $,_ = mars_handles
         )


let, sql_filter = "
 select 1 as class,    -- od, see /usr/local/apps/odb_api/codes/class.table
        1025 as stream, -- oper, see /usr/local/apps/odb_api/codes/stream.table
        263 as type,    -- ofb, currently hardcoded! 
        17 as groupid,  -- conv, see /usr/local/apps/odb_api/codes/group.txt
        reporttype@hdr as reportype,
        ops_obsgroup@hdr, ops_subtype@hdr, fg_depar@body, an_depar@body, 
        corvalue@body, datum_status@body, datum_event1@body, derived_value@body,
        obsvalue@body, obs_error@errstat, final_obs_error@errstat, fg_error@errstat,
        pges_buddy@errstat, pges_final@errstat, vertco_reference_1@body,
        vertco_reference_2@body, vertco_type@body, date@hdr, time@hdr, 
        lat@hdr, lon@hdr, ops_datum_flags@body, ops_obstype@hdr, orography@modsurf,
        lsm@modsurf, pstar@modsurf, statid@hdr, stalt@hdr, ident@hdr, 
        report_pge@hdr, report_status@hdr, report_event1@hdr, hawson_corr@conv, 
        codetype@hdr, used_in_runid@hdr,
        -- reporttype@hdr,
        andate@desc as andate, antime@desc, expver@desc, model@desc, 
        back_frct_length@desc, ops_report_flags@hdr, solar_zenith@hdr, varno@body,
        receipt_date@hdr, receipt_time@hdr, station_type@conv, 
        pressure_sensor_alt@conv, buoy_identifier@conv, ob_practice@conv,
        sst_measurement_method@conv, road_site_identifier@conv,
        wmo_block_number@conv, wmo_region_number@conv, wmo_station_number@conv,
        position_accuracy_flag@conv, buoy_speed@conv, buoy_direction@conv,
        hours_since_last_position@conv, bogus_identity@conv, bgvalue@body"


test, label = "Check archiving and retrieving from server works (Met Office)",
do = (
    system, values = "rm -rf " / (path, _ = (getenv, values = TEST_DATA_DIRECTORY)/"odb_root/*")

    split_and_archive,
        filter = ($,_ = sql_filter),
        source = (path, _ = (getenv, values = TEST_DATA_DIRECTORY)/"20150218_glu_surface_odb2"),
        output_schema = (path, _ = (getenv, values = TEST_DATA_DIRECTORY)/"odb_root/{andate}/{antime}/{reportype}.odb")

    println, values = OK

), expect = OK

